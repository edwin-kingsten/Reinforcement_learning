{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Q learning.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "e0j3tk1YfguY"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iw7uODhtfmqr"
      },
      "source": [
        "## Defining Grid World"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XjKC2GCFfrwI"
      },
      "source": [
        "class Grid():\n",
        "    def __init__(self , rows , cols , start):\n",
        "        self.rows = rows\n",
        "        self.cols = cols\n",
        "        self.start = start\n",
        "        self.i = start[0]\n",
        "        self.j = start[1]\n",
        "\n",
        "    def set(self, actions , rewards):\n",
        "        self.actions = actions\n",
        "        self.rewards = rewards\n",
        "\n",
        "    def reset(self):\n",
        "        self.i  , self.j = self.start\n",
        "\n",
        "    def set_state(self, s):\n",
        "        self.i = s[0]\n",
        "        self.j = s[1]\n",
        "\n",
        "    def is_terminal(self, s):\n",
        "        return s in self.rewards\n",
        "\n",
        "    def current_state(self):\n",
        "        return (self.i , self.j)\n",
        "\n",
        "    def all_states(self):\n",
        "        return set(self.actions.keys()) | set(self.rewards.keys())\n",
        "\n",
        "    def move(self , a):\n",
        "        if a in self.actions[(self.i , self.j)]:\n",
        "            if a == \"U\":\n",
        "                self.i -= 1\n",
        "\n",
        "            elif a == \"D\":\n",
        "                self.i += 1\n",
        "\n",
        "            elif a == \"R\":\n",
        "                self.j += 1\n",
        "\n",
        "            elif a == \"L\":\n",
        "                self.j -= 1\n",
        "        \n",
        "        return self.rewards.get((self.i , self.j) , 0)\n",
        "\n",
        "    def game_over(self):\n",
        "        return (self.i , self.j) in self.rewards"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VDNffxNufrsu"
      },
      "source": [
        "def initialize_grid():\n",
        "    rows , cols = 3 , 4\n",
        "    start = (2 , 0)\n",
        "    g = Grid(rows , cols , start)\n",
        "    \n",
        "    # reward for termination state\n",
        "    rewards = {(0, 3): 1 , (1 , 3) : -1}\n",
        "    \n",
        "    # possible actions can be performed for each state\n",
        "    actions = {\n",
        "              (0, 0):[\"D\" , \"R\"],\n",
        "              (0, 1):[\"R\"],\n",
        "              (0, 2):[\"R\"],\n",
        "              (1, 0):[\"U\" ,\"D\"],\n",
        "              (1, 2):[\"U\" ,\"D\" ,\"R\"],\n",
        "              (2, 0):[\"U\" , \"R\"],\n",
        "              (2, 1):[\"R\" , \"L\"],\n",
        "              (2, 2):[\"R\" , \"L\" ,\"U\"],\n",
        "              (2, 3):[\"L\" , \"U\"]\n",
        "    }\n",
        "\n",
        "    g.set(actions , rewards)\n",
        "\n",
        "    return g"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9kSefXqIfrqM"
      },
      "source": [
        "## Visualization Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GfGJZxHyfrnr"
      },
      "source": [
        "def print_values(V, g):\n",
        "    print(\"Printing Values\")\n",
        "    for i in range(g.rows):\n",
        "        print(\"---------------------------\")\n",
        "        for j in range(g.cols):\n",
        "            v = V.get((i,j), 0)\n",
        "            if v >= 0:\n",
        "                print(\" %.2f|\" % v, end=\"\")\n",
        "            else:\n",
        "                print(\"%.2f|\" % v, end=\"\") # -ve sign takes up an extra space\n",
        "        print(\"\")\n",
        "\n",
        "\n",
        "def print_policy(P, g):\n",
        "    print(\"Printing Policy\")\n",
        "    for i in range(g.rows):\n",
        "        print(\"---------------------------\")\n",
        "        for j in range(g.cols):\n",
        "            a = P.get((i,j), ' ')\n",
        "            print(\"  %s  |\" % a, end=\"\") \n",
        "        print(\"\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8kdtIcWfrlL"
      },
      "source": [
        "## Define Epsilon Greedy random action\n",
        "def random_action(a , eps = 0.3):\n",
        "    if np.random.random() < (1 - eps) :\n",
        "        return a\n",
        "    else:\n",
        "        # print(\"random choice\")\n",
        "        return np.random.choice(ACTION_SPACE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAnwtIMsfrgh"
      },
      "source": [
        "# function for finding maximum value and its corresponding key in dictionary\n",
        "def max_dict(d):\n",
        "    # find max val\n",
        "    max_val = max(d.values())\n",
        "\n",
        "    # find keys corresponding to max val\n",
        "    for key , val in d.items():\n",
        "        # print(key)\n",
        "        if val == max_val:\n",
        "            max_key = key\n",
        "            break\n",
        "\n",
        "    return max_key , max_val"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mhHeHBFfreF"
      },
      "source": [
        "## Initialize Grid"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QHahwPQfrbg"
      },
      "source": [
        "grid = initialize_grid()\n",
        "ACTION_SPACE = (\"U\" , \"D\" , \"R\" , \"L\")\n",
        "gamma = 0.9"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L9T2W1FpfrZG"
      },
      "source": [
        "## Initialize Policy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DVl5aQxFgHpi"
      },
      "source": [
        "Policy = {}\n",
        "for i in grid.actions.keys():\n",
        "    Policy[i] = np.random.choice(ACTION_SPACE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eAG-cQs_gHmB"
      },
      "source": [
        "## Initialize Q values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pd1p6dexgHjc"
      },
      "source": [
        "Q = {}\n",
        "sample_counts = {}\n",
        "\n",
        "for s in grid.all_states():\n",
        "        Q[s] = {}\n",
        "        sample_counts[s] = {}\n",
        "        for a in ACTION_SPACE:\n",
        "            Q[s][a] = 0.0\n",
        "            sample_counts[s][a] = 0.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VRKG0-ycgHg_"
      },
      "source": [
        "## Both policy improvement and Policy evaluation at the same step"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Ji4I7DYQgHeh",
        "outputId": "a8821c52-3e48-47bd-cbeb-23da703c2ca2"
      },
      "source": [
        "delta = []\n",
        "gamma = 0.9\n",
        "biggest_change = 0\n",
        "alpha = 0.3\n",
        "eps = 1\n",
        "epochs = 10000\n",
        "\n",
        "for it in range(epochs):\n",
        "\n",
        "    if it%1000 == 0:\n",
        "        print(\"iteration \" , it)\n",
        "        for sv in grid.actions.keys():\n",
        "            Policy[sv] , _ = max_dict(Q[sv])\n",
        "        print_policy(Policy , grid)\n",
        "    \n",
        "    # play game\n",
        "    grid.reset()\n",
        "    s = grid.current_state()\n",
        "   \n",
        "    while not grid.game_over():\n",
        "        # choosing action randomly\n",
        "        # epsilon greedy can also be used here\n",
        "        a = np.random.choice(ACTION_SPACE)\n",
        "\n",
        "        # perform action and get next state + reward\n",
        "        r = grid.move(a)\n",
        "        \n",
        "        s2 = grid.current_state()\n",
        "        a2 = max_dict(Q[s2])[0]\n",
        "\n",
        "        #update Q\n",
        "        old_q = Q[s][a]\n",
        "        sample_counts[s][a] += 1\n",
        "        Q[s][a] = Q[s][a] + (r + gamma*Q[s2][a2] - Q[s][a])/sample_counts[s][a]  # running Q mean\n",
        "        biggest_change = max(biggest_change , np.abs(old_q - Q[s][a]))\n",
        "\n",
        "        s = s2\n",
        "        a = a2\n",
        "\n",
        "    delta.append(biggest_change)\n",
        "\n",
        "plt.plot(delta)\n",
        "\n",
        "V = {}\n",
        "for sv in grid.actions.keys():\n",
        "    Policy[sv] , V[sv] = max_dict(Q[sv])\n",
        "\n",
        "print_policy(Policy , grid)\n",
        "print_values(V ,grid)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iteration  0\n",
            "Printing Policy\n",
            "---------------------------\n",
            "  U  |  U  |  U  |     |\n",
            "---------------------------\n",
            "  U  |     |  U  |     |\n",
            "---------------------------\n",
            "  U  |  U  |  U  |  U  |\n",
            "iteration  1000\n",
            "Printing Policy\n",
            "---------------------------\n",
            "  R  |  R  |  R  |     |\n",
            "---------------------------\n",
            "  U  |     |  U  |     |\n",
            "---------------------------\n",
            "  U  |  R  |  U  |  L  |\n",
            "iteration  2000\n",
            "Printing Policy\n",
            "---------------------------\n",
            "  R  |  R  |  R  |     |\n",
            "---------------------------\n",
            "  U  |     |  U  |     |\n",
            "---------------------------\n",
            "  U  |  R  |  U  |  L  |\n",
            "iteration  3000\n",
            "Printing Policy\n",
            "---------------------------\n",
            "  R  |  R  |  R  |     |\n",
            "---------------------------\n",
            "  U  |     |  U  |     |\n",
            "---------------------------\n",
            "  U  |  R  |  U  |  L  |\n",
            "iteration  4000\n",
            "Printing Policy\n",
            "---------------------------\n",
            "  R  |  R  |  R  |     |\n",
            "---------------------------\n",
            "  U  |     |  U  |     |\n",
            "---------------------------\n",
            "  U  |  R  |  U  |  L  |\n",
            "iteration  5000\n",
            "Printing Policy\n",
            "---------------------------\n",
            "  R  |  R  |  R  |     |\n",
            "---------------------------\n",
            "  U  |     |  U  |     |\n",
            "---------------------------\n",
            "  U  |  R  |  U  |  L  |\n",
            "iteration  6000\n",
            "Printing Policy\n",
            "---------------------------\n",
            "  R  |  R  |  R  |     |\n",
            "---------------------------\n",
            "  U  |     |  U  |     |\n",
            "---------------------------\n",
            "  U  |  R  |  U  |  L  |\n",
            "iteration  7000\n",
            "Printing Policy\n",
            "---------------------------\n",
            "  R  |  R  |  R  |     |\n",
            "---------------------------\n",
            "  U  |     |  U  |     |\n",
            "---------------------------\n",
            "  U  |  R  |  U  |  L  |\n",
            "iteration  8000\n",
            "Printing Policy\n",
            "---------------------------\n",
            "  R  |  R  |  R  |     |\n",
            "---------------------------\n",
            "  U  |     |  U  |     |\n",
            "---------------------------\n",
            "  U  |  R  |  U  |  L  |\n",
            "iteration  9000\n",
            "Printing Policy\n",
            "---------------------------\n",
            "  R  |  R  |  R  |     |\n",
            "---------------------------\n",
            "  U  |     |  U  |     |\n",
            "---------------------------\n",
            "  U  |  R  |  U  |  L  |\n",
            "Printing Policy\n",
            "---------------------------\n",
            "  R  |  R  |  R  |     |\n",
            "---------------------------\n",
            "  U  |     |  U  |     |\n",
            "---------------------------\n",
            "  U  |  R  |  U  |  L  |\n",
            "Printing Values\n",
            "---------------------------\n",
            " 0.81| 0.90| 1.00| 0.00|\n",
            "---------------------------\n",
            " 0.72| 0.00| 0.90| 0.00|\n",
            "---------------------------\n",
            " 0.63| 0.72| 0.81| 0.72|\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}