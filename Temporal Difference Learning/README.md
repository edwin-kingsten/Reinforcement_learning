### TD Overcomes problems faced by both Monte carlo and Dynamic Progamming.
### In this method we don't need to wait till the end of game to update Q value.
### We can update Q value after each step
### In this method , Randomness involves in choosing the action.
### Methods : SARSA , Q-learning
### SARSA : actions are choosen randomly for next state only
### Q-learning : actions are choosen randomly for current state.
